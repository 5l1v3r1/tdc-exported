
# Report Suggests Rampant Negligence In Uber Self Driving Car Fatality

Published at: **2019-11-06T13:35:00+00:00**

Author: **Karl Bode**

Original: [Techdirt](https://www.techdirt.com/articles/20191106/07100543337/report-suggests-rampant-negligence-uber-self-driving-car-fatality.shtml)

Earlier this year you might recall that a self-driving Uber in Tempe, Arizona killed a woman who was trying to cross the street with her bike outside of a crosswalk. The driver wasn't paying attention, and the car itself failed to stop for the jaywalking pedestrian. Initial reporting on the subject, most of it based on anonymous Uber sources who spoke to the paywalled news outlet The Information, strongly pushed the idea that the car's sensors worked as intended and detected the woman, but bugs in the system software failed to properly identify the woman as something to avoid:
Thanks to that report, a narrative emerged that the vehicle largely worked as designed, and the only real problem was a modest quirk in uncooked programming.
But a new report by Bloomberg this week shatters that understanding. According to NTSB findings seen by Bloomberg, the vehicle in question wasn't even programmed to detect jaywalkers. Like, at all:
Assuming Bloomberg's read of the 400 page report (only a part of which has been made public) is accurate, that's a far cry from a bug. The NTSB report found that Uber staff had also disabled Volvo auto-detection and breaking software that could have at least slowed the vehicle if not avoided the pedestrian impact altogether. Investigators also noted that despite the fact that Uber was conducting risky trials on public streets, the company had little to no real system in place for dealing with safety issues. Again, not just underwhelming public safety protocols, but none whatsoever:
Again, that's not just buggy or "poorly tuned" software, it's total negligence. Despite the fact the driver was distracted, the car was never adequately programmed to detect jaywalkers, some safety features were disabled, and Uber had little to no safety protocols in place, prosecutors have already absolved Uber of criminal liability (though the driver still may face a lawsuit). The NTSB also hasn't formally affixed blame for the crash (yet):
Self driving cars are remarkably safe, and most accidents involve autonomous vehicles getting confused when people actually follow the law (like rear ending a human-driven vehicle that stopped at a red light before turning right). But that's only true when the people designing and conducting trials are competent. If the NTSB report is anything to go by, Uber fell well short, yet got to enjoy a lot of press suggesting the problem was random bad programming luck, not total negligence and incompetence. Later this month we'll get to see if Uber faces anything resembling accountability for its failures.
