
# Schwachstelle in Smart Speakern: Forschende steuern Alexa, Siri und Google Assistant mit Licht

Published at: **2019-11-06T14:49:00+00:00**

Author: **Tanja Banner**

Original: [Frankfurter Rundschau](https://www.fr.de/wissen/alexa-siri-google-assistant-sicherheitsluecke-smart-speaker-zr-13198042.html)


        Smart Speaker sind beliebt - doch nun haben Forschende in Alexa, Siri und Google Assistant eine Sicherheitslücke entdeckt, die Besitzer von Smart Speakern aufhorchen lassen sollte.
      
Sprach-Assistenten wie Siri, Alexa oder Google Assistant sind beliebt. Der Nutzer spricht ein Kommando - und das Gerät führt es aus. Das reicht von einfachen Aufgaben wie dem Abspielen eines Lieds oder dem Programmieren der Erinnerungsfunktion bis hin zum Steuern externer Geräte wie Lampen, Türschlösser oder Garagentore.
Vor diesem Hintergrund ist eine Schwachstelle, die Forschende in Mikrofonen entdeckt haben, besonders heikel: Ihnen ist es gelungen, verschiedene Sprachassistenten zu hacken - und zwar nicht per Sprachkommandos, sondern mit Lichtsignalen. „Light Commands“ haben Forschende der University of Michigan und der University of Electro Communications in Tokio die Schwachstelle genannt, die sie gefunden haben.
Im Versuch ist es den Forschenden gelungen, Siri, Google Assistant* und Alexa mit Hilfe eines Laserstrahls auszutricksen. Das gelang in unterschiedlichen Szenarien: aus nächster Nähe, über eine Distanz von 110 Metern und sogar über eine lange Distanz und durch ein geschlossenes Fenster.
„Es ist möglich, Mikrofone dazu zu bringen, auf Licht so zu reagieren, als ob es Klang wäre“, erklärt der Forscher Takeshi Sugawara gegenüber dem Magazin „Wired“. „Das bedeutet, dass jedes Gerät, das auf Klang reagiert, auch auf Lichtkommandos reagiert.“
